{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWoMBFdgWMVO",
        "outputId": "6a10a4a1-bed3-455a-f116-972da2d656af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: recordlinkage in /usr/local/lib/python3.7/dist-packages (0.15)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (0.8.10)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: py_stringmatching in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.0.2)\n",
            "Requirement already satisfied: jellyfish>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (0.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1 in /usr/local/lib/python3.7/dist-packages (from recordlinkage) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.0->recordlinkage) (3.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas recordlinkage tabulate sklearn py_stringmatching matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGky6ZqFVvIC",
        "outputId": "f21945be-b98d-4392-ed42-78eb9f857fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "BK 3\n",
            "1794\n",
            "prefix qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7324321904932415,\n",
            " 'FN': 24,\n",
            " 'FP': 2965,\n",
            " 'TN': 4471,\n",
            " 'TP': 4091,\n",
            " 'precision': 0.5797902494331065,\n",
            " 'recall': 0.9941676792223573}\n",
            "0.8673679828643799\n",
            "BK 4\n",
            "1794\n",
            "prefix qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7324372759856631,\n",
            " 'FN': 19,\n",
            " 'FP': 2967,\n",
            " 'TN': 4471,\n",
            " 'TP': 4087,\n",
            " 'precision': 0.5793875815140346,\n",
            " 'recall': 0.9953726254262055}\n",
            "1.3717989921569824\n",
            "BK 5\n",
            "1794\n",
            "prefix qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7321620652563643,\n",
            " 'FN': 18,\n",
            " 'FP': 2970,\n",
            " 'TN': 4471,\n",
            " 'TP': 4084,\n",
            " 'precision': 0.5789622908987808,\n",
            " 'recall': 0.9956118966357874}\n",
            "1.0984561443328857\n",
            "BK 6\n",
            "1794\n",
            "prefix qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7309107222969942,\n",
            " 'FN': 18,\n",
            " 'FP': 2981,\n",
            " 'TN': 4471,\n",
            " 'TP': 4073,\n",
            " 'precision': 0.5774028919761838,\n",
            " 'recall': 0.995600097775605}\n",
            "0.3432347774505615\n",
            "BK 7\n",
            "1794\n",
            "prefix qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7301615798922801,\n",
            " 'FN': 19,\n",
            " 'FP': 2987,\n",
            " 'TN': 4471,\n",
            " 'TP': 4067,\n",
            " 'precision': 0.5765523107456763,\n",
            " 'recall': 0.995349975526187}\n",
            "0.31298160552978516\n",
            "BK 3\n",
            "1794\n",
            "prefix qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2243365047571357,\n",
            " 'FN': 16,\n",
            " 'FP': 6180,\n",
            " 'TN': 4471,\n",
            " 'TP': 896,\n",
            " 'precision': 0.12662521198417184,\n",
            " 'recall': 0.9824561403508771}\n",
            "0.4165465831756592\n",
            "BK 4\n",
            "1794\n",
            "prefix qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2243365047571357,\n",
            " 'FN': 16,\n",
            " 'FP': 6180,\n",
            " 'TN': 4471,\n",
            " 'TP': 896,\n",
            " 'precision': 0.12662521198417184,\n",
            " 'recall': 0.9824561403508771}\n",
            "0.42540812492370605\n",
            "BK 5\n",
            "1794\n",
            "prefix qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2243365047571357,\n",
            " 'FN': 16,\n",
            " 'FP': 6180,\n",
            " 'TN': 4471,\n",
            " 'TP': 896,\n",
            " 'precision': 0.12662521198417184,\n",
            " 'recall': 0.9824561403508771}\n",
            "0.3824899196624756\n",
            "BK 6\n",
            "1794\n",
            "prefix qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2243365047571357,\n",
            " 'FN': 16,\n",
            " 'FP': 6180,\n",
            " 'TN': 4471,\n",
            " 'TP': 896,\n",
            " 'precision': 0.12662521198417184,\n",
            " 'recall': 0.9824561403508771}\n",
            "0.3736286163330078\n",
            "BK 7\n",
            "1794\n",
            "prefix qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2243365047571357,\n",
            " 'FN': 16,\n",
            " 'FP': 6180,\n",
            " 'TN': 4471,\n",
            " 'TP': 896,\n",
            " 'precision': 0.12662521198417184,\n",
            " 'recall': 0.9824561403508771}\n",
            "0.3322298526763916\n",
            "BK 3\n",
            "1794\n",
            "prefix string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7322179475709046,\n",
            " 'FN': 25,\n",
            " 'FP': 2968,\n",
            " 'TN': 4470,\n",
            " 'TP': 4092,\n",
            " 'precision': 0.5796033994334278,\n",
            " 'recall': 0.9939276171969881}\n",
            "8.832611560821533\n",
            "BK 4\n",
            "1794\n",
            "prefix string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7322179475709046,\n",
            " 'FN': 25,\n",
            " 'FP': 2968,\n",
            " 'TN': 4470,\n",
            " 'TP': 4092,\n",
            " 'precision': 0.5796033994334278,\n",
            " 'recall': 0.9939276171969881}\n",
            "8.329570770263672\n",
            "BK 5\n",
            "1794\n",
            "prefix string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7322179475709046,\n",
            " 'FN': 25,\n",
            " 'FP': 2968,\n",
            " 'TN': 4470,\n",
            " 'TP': 4092,\n",
            " 'precision': 0.5796033994334278,\n",
            " 'recall': 0.9939276171969881}\n",
            "8.560116291046143\n",
            "BK 6\n",
            "1794\n",
            "prefix string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7322179475709046,\n",
            " 'FN': 25,\n",
            " 'FP': 2968,\n",
            " 'TN': 4470,\n",
            " 'TP': 4092,\n",
            " 'precision': 0.5796033994334278,\n",
            " 'recall': 0.9939276171969881}\n",
            "8.523535013198853\n",
            "BK 7\n",
            "1794\n",
            "prefix string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7322179475709046,\n",
            " 'FN': 25,\n",
            " 'FP': 2968,\n",
            " 'TN': 4470,\n",
            " 'TP': 4092,\n",
            " 'precision': 0.5796033994334278,\n",
            " 'recall': 0.9939276171969881}\n",
            "8.575989723205566\n",
            "BK 3\n",
            "1794\n",
            "prefix string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.22456404466189936,\n",
            " 'FN': 14,\n",
            " 'FP': 6167,\n",
            " 'TN': 4471,\n",
            " 'TP': 895,\n",
            " 'precision': 0.12673463608043048,\n",
            " 'recall': 0.9845984598459846}\n",
            "8.217806577682495\n",
            "BK 4\n",
            "1794\n",
            "prefix string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.22514071294559101,\n",
            " 'FN': 10,\n",
            " 'FP': 6185,\n",
            " 'TN': 4471,\n",
            " 'TP': 900,\n",
            " 'precision': 0.12702893436838392,\n",
            " 'recall': 0.989010989010989}\n",
            "8.626222848892212\n",
            "BK 5\n",
            "1794\n",
            "prefix string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.21415106195802439,\n",
            " 'FN': 15,\n",
            " 'FP': 6238,\n",
            " 'TN': 4470,\n",
            " 'TP': 852,\n",
            " 'precision': 0.12016925246826517,\n",
            " 'recall': 0.9826989619377162}\n",
            "8.85507082939148\n",
            "BK 6\n",
            "1794\n",
            "prefix string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.20820668693009117,\n",
            " 'FN': 12,\n",
            " 'FP': 6240,\n",
            " 'TN': 4469,\n",
            " 'TP': 822,\n",
            " 'precision': 0.11639762107051826,\n",
            " 'recall': 0.9856115107913669}\n",
            "8.613692998886108\n",
            "BK 7\n",
            "1794\n",
            "prefix string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2061464525104338,\n",
            " 'FN': 9,\n",
            " 'FP': 6268,\n",
            " 'TN': 4471,\n",
            " 'TP': 815,\n",
            " 'precision': 0.11506423831709728,\n",
            " 'recall': 0.9890776699029126}\n",
            "8.997320890426636\n",
            "BK 3\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7481912828657138,\n",
            " 'FN': 35,\n",
            " 'FP': 2819,\n",
            " 'TN': 4471,\n",
            " 'TP': 4240,\n",
            " 'precision': 0.6006516503754072,\n",
            " 'recall': 0.991812865497076}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7465323791854405,\n",
            " 'FN': 35,\n",
            " 'FP': 2834,\n",
            " 'TN': 4471,\n",
            " 'TP': 4225,\n",
            " 'precision': 0.5985267034990792,\n",
            " 'recall': 0.9917840375586855}\n",
            "71.67454814910889\n",
            "BK 4\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7483642793987622,\n",
            " 'FN': 25,\n",
            " 'FP': 2821,\n",
            " 'TN': 4471,\n",
            " 'TP': 4232,\n",
            " 'precision': 0.6000283567276337,\n",
            " 'recall': 0.994127319708715}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7467020805666225,\n",
            " 'FN': 25,\n",
            " 'FP': 2836,\n",
            " 'TN': 4471,\n",
            " 'TP': 4217,\n",
            " 'precision': 0.5979016021551113,\n",
            " 'recall': 0.9941065535124941}\n",
            "74.8440408706665\n",
            "BK 5\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7478322420810477,\n",
            " 'FN': 23,\n",
            " 'FP': 2827,\n",
            " 'TN': 4471,\n",
            " 'TP': 4226,\n",
            " 'precision': 0.5991776548986247,\n",
            " 'recall': 0.9945869616380325}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7461681580579429,\n",
            " 'FN': 23,\n",
            " 'FP': 2842,\n",
            " 'TN': 4471,\n",
            " 'TP': 4211,\n",
            " 'precision': 0.5970509003261024,\n",
            " 'recall': 0.9945677846008503}\n",
            "78.01111721992493\n",
            "BK 6\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7466123461163757,\n",
            " 'FN': 23,\n",
            " 'FP': 2838,\n",
            " 'TN': 4471,\n",
            " 'TP': 4215,\n",
            " 'precision': 0.597618034878775,\n",
            " 'recall': 0.9945729117508258}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7449450159631074,\n",
            " 'FN': 23,\n",
            " 'FP': 2853,\n",
            " 'TN': 4471,\n",
            " 'TP': 4200,\n",
            " 'precision': 0.5954912803062526,\n",
            " 'recall': 0.9945536348567369}\n",
            "72.75200319290161\n",
            "BK 7\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7454142667257421,\n",
            " 'FN': 26,\n",
            " 'FP': 2847,\n",
            " 'TN': 4471,\n",
            " 'TP': 4206,\n",
            " 'precision': 0.5963419821352616,\n",
            " 'recall': 0.9938563327032136}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7437444543034606,\n",
            " 'FN': 26,\n",
            " 'FP': 2862,\n",
            " 'TN': 4471,\n",
            " 'TP': 4191,\n",
            " 'precision': 0.5942152275627393,\n",
            " 'recall': 0.9938344794877876}\n",
            "76.67781519889832\n",
            "BK 3\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2610551274451689,\n",
            " 'FN': 82,\n",
            " 'FP': 6151,\n",
            " 'TN': 4466,\n",
            " 'TP': 1101,\n",
            " 'precision': 0.15182018753447324,\n",
            " 'recall': 0.9306846999154691}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26831295262970434,\n",
            " 'FN': 70,\n",
            " 'FP': 6093,\n",
            " 'TN': 4468,\n",
            " 'TP': 1130,\n",
            " 'precision': 0.1564446905717846,\n",
            " 'recall': 0.9416666666666667}\n",
            "75.03897094726562\n",
            "BK 4\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2610551274451689,\n",
            " 'FN': 82,\n",
            " 'FP': 6151,\n",
            " 'TN': 4466,\n",
            " 'TP': 1101,\n",
            " 'precision': 0.15182018753447324,\n",
            " 'recall': 0.9306846999154691}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26831295262970434,\n",
            " 'FN': 70,\n",
            " 'FP': 6093,\n",
            " 'TN': 4468,\n",
            " 'TP': 1130,\n",
            " 'precision': 0.1564446905717846,\n",
            " 'recall': 0.9416666666666667}\n",
            "76.22497892379761\n",
            "BK 5\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2610551274451689,\n",
            " 'FN': 82,\n",
            " 'FP': 6151,\n",
            " 'TN': 4466,\n",
            " 'TP': 1101,\n",
            " 'precision': 0.15182018753447324,\n",
            " 'recall': 0.9306846999154691}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26831295262970434,\n",
            " 'FN': 70,\n",
            " 'FP': 6093,\n",
            " 'TN': 4468,\n",
            " 'TP': 1130,\n",
            " 'precision': 0.1564446905717846,\n",
            " 'recall': 0.9416666666666667}\n",
            "82.4908037185669\n",
            "BK 6\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2610551274451689,\n",
            " 'FN': 82,\n",
            " 'FP': 6151,\n",
            " 'TN': 4466,\n",
            " 'TP': 1101,\n",
            " 'precision': 0.15182018753447324,\n",
            " 'recall': 0.9306846999154691}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26831295262970434,\n",
            " 'FN': 70,\n",
            " 'FP': 6093,\n",
            " 'TN': 4468,\n",
            " 'TP': 1130,\n",
            " 'precision': 0.1564446905717846,\n",
            " 'recall': 0.9416666666666667}\n",
            "86.19205403327942\n",
            "BK 7\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2610551274451689,\n",
            " 'FN': 82,\n",
            " 'FP': 6151,\n",
            " 'TN': 4466,\n",
            " 'TP': 1101,\n",
            " 'precision': 0.15182018753447324,\n",
            " 'recall': 0.9306846999154691}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram qgram gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26831295262970434,\n",
            " 'FN': 70,\n",
            " 'FP': 6093,\n",
            " 'TN': 4468,\n",
            " 'TP': 1130,\n",
            " 'precision': 0.1564446905717846,\n",
            " 'recall': 0.9416666666666667}\n",
            "81.23690176010132\n",
            "BK 3\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7479073046083355,\n",
            " 'FN': 38,\n",
            " 'FP': 2823,\n",
            " 'TN': 4467,\n",
            " 'TP': 4244,\n",
            " 'precision': 0.6005377104853544,\n",
            " 'recall': 0.9911256422232602}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7462502205752602,\n",
            " 'FN': 38,\n",
            " 'FP': 2838,\n",
            " 'TN': 4467,\n",
            " 'TP': 4229,\n",
            " 'precision': 0.5984151690957974,\n",
            " 'recall': 0.991094445746426}\n",
            "92.9336040019989\n",
            "BK 4\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7479073046083355,\n",
            " 'FN': 38,\n",
            " 'FP': 2823,\n",
            " 'TN': 4467,\n",
            " 'TP': 4244,\n",
            " 'precision': 0.6005377104853544,\n",
            " 'recall': 0.9911256422232602}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7462502205752602,\n",
            " 'FN': 38,\n",
            " 'FP': 2838,\n",
            " 'TN': 4467,\n",
            " 'TP': 4229,\n",
            " 'precision': 0.5984151690957974,\n",
            " 'recall': 0.991094445746426}\n",
            "91.06035256385803\n",
            "BK 5\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7479073046083355,\n",
            " 'FN': 38,\n",
            " 'FP': 2823,\n",
            " 'TN': 4467,\n",
            " 'TP': 4244,\n",
            " 'precision': 0.6005377104853544,\n",
            " 'recall': 0.9911256422232602}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7462502205752602,\n",
            " 'FN': 38,\n",
            " 'FP': 2838,\n",
            " 'TN': 4467,\n",
            " 'TP': 4229,\n",
            " 'precision': 0.5984151690957974,\n",
            " 'recall': 0.991094445746426}\n",
            "90.93670177459717\n",
            "BK 6\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7479073046083355,\n",
            " 'FN': 38,\n",
            " 'FP': 2823,\n",
            " 'TN': 4467,\n",
            " 'TP': 4244,\n",
            " 'precision': 0.6005377104853544,\n",
            " 'recall': 0.9911256422232602}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7462502205752602,\n",
            " 'FN': 38,\n",
            " 'FP': 2838,\n",
            " 'TN': 4467,\n",
            " 'TP': 4229,\n",
            " 'precision': 0.5984151690957974,\n",
            " 'recall': 0.991094445746426}\n",
            "97.11259436607361\n",
            "BK 7\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7479073046083355,\n",
            " 'FN': 38,\n",
            " 'FP': 2823,\n",
            " 'TN': 4467,\n",
            " 'TP': 4244,\n",
            " 'precision': 0.6005377104853544,\n",
            " 'recall': 0.9911256422232602}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact prefix match:\n",
            "Metrics:\n",
            "{'F1': 0.7462502205752602,\n",
            " 'FN': 38,\n",
            " 'FP': 2838,\n",
            " 'TN': 4467,\n",
            " 'TP': 4229,\n",
            " 'precision': 0.5984151690957974,\n",
            " 'recall': 0.991094445746426}\n",
            "94.89846658706665\n",
            "BK 3\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26980168626053913,\n",
            " 'FN': 69,\n",
            " 'FP': 6080,\n",
            " 'TN': 4469,\n",
            " 'TP': 1136,\n",
            " 'precision': 0.1574279379157428,\n",
            " 'recall': 0.9427385892116182}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2627876475497794,\n",
            " 'FN': 72,\n",
            " 'FP': 6111,\n",
            " 'TN': 4465,\n",
            " 'TP': 1102,\n",
            " 'precision': 0.1527797033134618,\n",
            " 'recall': 0.938671209540034}\n",
            "97.2102677822113\n",
            "BK 4\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.26057007125890735,\n",
            " 'FN': 88,\n",
            " 'FP': 6138,\n",
            " 'TN': 4469,\n",
            " 'TP': 1097,\n",
            " 'precision': 0.15162404975812024,\n",
            " 'recall': 0.9257383966244725}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2662862577270566,\n",
            " 'FN': 70,\n",
            " 'FP': 6102,\n",
            " 'TN': 4468,\n",
            " 'TP': 1120,\n",
            " 'precision': 0.15508169482137912,\n",
            " 'recall': 0.9411764705882353}\n",
            "95.64522361755371\n",
            "BK 5\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.25135037810586963,\n",
            " 'FN': 75,\n",
            " 'FP': 6162,\n",
            " 'TN': 4467,\n",
            " 'TP': 1047,\n",
            " 'precision': 0.14523512276321265,\n",
            " 'recall': 0.9331550802139037}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2595912513445679,\n",
            " 'FN': 60,\n",
            " 'FP': 6135,\n",
            " 'TN': 4470,\n",
            " 'TP': 1086,\n",
            " 'precision': 0.1503946821769838,\n",
            " 'recall': 0.9476439790575916}\n",
            "88.79961943626404\n",
            "BK 6\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2428399518652226,\n",
            " 'FN': 77,\n",
            " 'FP': 6215,\n",
            " 'TN': 4467,\n",
            " 'TP': 1009,\n",
            " 'precision': 0.1396733111849391,\n",
            " 'recall': 0.929097605893186}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.24952107279693492,\n",
            " 'FN': 69,\n",
            " 'FP': 6199,\n",
            " 'TN': 4468,\n",
            " 'TP': 1042,\n",
            " 'precision': 0.1439027758596879,\n",
            " 'recall': 0.9378937893789379}\n",
            "93.10746121406555\n",
            "BK 7\n",
            "Qgram_BK 3\n",
            "2360\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.2390859891761876,\n",
            " 'FN': 75,\n",
            " 'FP': 6252,\n",
            " 'TN': 4467,\n",
            " 'TP': 994,\n",
            " 'precision': 0.13717913331493237,\n",
            " 'recall': 0.9298409728718429}\n",
            "Qgram_BK 4\n",
            "2345\n",
            "qgram string_exact gradient match:\n",
            "Metrics:\n",
            "{'F1': 0.23953823953823955,\n",
            " 'FN': 81,\n",
            " 'FP': 6243,\n",
            " 'TN': 4466,\n",
            " 'TP': 996,\n",
            " 'precision': 0.13758806464981352,\n",
            " 'recall': 0.924791086350975}\n",
            "94.89785885810852\n",
            "+---+------+----+------+------+---------------------+--------------------+---------------------+----------+--------------+-----------+---------------------+-----------------------------------------------------------------------+--------------+-------------+\n",
            "|   |  TP  | FN |  FP  |  TN  |      precision      |       recall       |         F1          | Block_Al |   Match_Al   | Classi_Al |      Duration       |                                Dataset                                | Blocking Key | Block_Qgram |\n",
            "+---+------+----+------+------+---------------------+--------------------+---------------------+----------+--------------+-----------+---------------------+-----------------------------------------------------------------------+--------------+-------------+\n",
            "| 0 | 4091 | 24 | 2965 | 4471 | 0.5797902494331065  | 0.9941676792223573 | 0.7324321904932415  |  prefix  |    qgram     |  prefix   | 0.8673679828643799  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |             |\n",
            "| 0 | 4087 | 19 | 2967 | 4471 | 0.5793875815140346  | 0.9953726254262055 | 0.7324372759856631  |  prefix  |    qgram     |  prefix   | 1.3717989921569824  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |             |\n",
            "| 0 | 4084 | 18 | 2970 | 4471 | 0.5789622908987808  | 0.9956118966357874 | 0.7321620652563643  |  prefix  |    qgram     |  prefix   | 1.0984561443328857  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |             |\n",
            "| 0 | 4073 | 18 | 2981 | 4471 | 0.5774028919761838  | 0.995600097775605  | 0.7309107222969942  |  prefix  |    qgram     |  prefix   | 0.3432347774505615  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |             |\n",
            "| 0 | 4067 | 19 | 2987 | 4471 | 0.5765523107456763  | 0.995349975526187  | 0.7301615798922801  |  prefix  |    qgram     |  prefix   | 0.31298160552978516 | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |             |\n",
            "| 0 | 896  | 16 | 6180 | 4471 | 0.12662521198417184 | 0.9824561403508771 | 0.2243365047571357  |  prefix  |    qgram     | gradient  | 0.4165465831756592  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |             |\n",
            "| 0 | 896  | 16 | 6180 | 4471 | 0.12662521198417184 | 0.9824561403508771 | 0.2243365047571357  |  prefix  |    qgram     | gradient  | 0.42540812492370605 | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |             |\n",
            "| 0 | 896  | 16 | 6180 | 4471 | 0.12662521198417184 | 0.9824561403508771 | 0.2243365047571357  |  prefix  |    qgram     | gradient  | 0.3824899196624756  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |             |\n",
            "| 0 | 896  | 16 | 6180 | 4471 | 0.12662521198417184 | 0.9824561403508771 | 0.2243365047571357  |  prefix  |    qgram     | gradient  | 0.3736286163330078  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |             |\n",
            "| 0 | 896  | 16 | 6180 | 4471 | 0.12662521198417184 | 0.9824561403508771 | 0.2243365047571357  |  prefix  |    qgram     | gradient  | 0.3322298526763916  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |             |\n",
            "| 0 | 4092 | 25 | 2968 | 4470 | 0.5796033994334278  | 0.9939276171969881 | 0.7322179475709046  |  prefix  | string_exact |  prefix   |  8.832611560821533  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |             |\n",
            "| 0 | 4092 | 25 | 2968 | 4470 | 0.5796033994334278  | 0.9939276171969881 | 0.7322179475709046  |  prefix  | string_exact |  prefix   |  8.329570770263672  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |             |\n",
            "| 0 | 4092 | 25 | 2968 | 4470 | 0.5796033994334278  | 0.9939276171969881 | 0.7322179475709046  |  prefix  | string_exact |  prefix   |  8.560116291046143  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |             |\n",
            "| 0 | 4092 | 25 | 2968 | 4470 | 0.5796033994334278  | 0.9939276171969881 | 0.7322179475709046  |  prefix  | string_exact |  prefix   |  8.523535013198853  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |             |\n",
            "| 0 | 4092 | 25 | 2968 | 4470 | 0.5796033994334278  | 0.9939276171969881 | 0.7322179475709046  |  prefix  | string_exact |  prefix   |  8.575989723205566  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |             |\n",
            "| 0 | 895  | 14 | 6167 | 4471 | 0.12673463608043048 | 0.9845984598459846 | 0.22456404466189936 |  prefix  | string_exact | gradient  |  8.217806577682495  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |             |\n",
            "| 0 | 900  | 10 | 6185 | 4471 | 0.12702893436838392 | 0.989010989010989  | 0.22514071294559101 |  prefix  | string_exact | gradient  |  8.626222848892212  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |             |\n",
            "| 0 | 852  | 15 | 6238 | 4470 | 0.12016925246826517 | 0.9826989619377162 | 0.21415106195802439 |  prefix  | string_exact | gradient  |  8.85507082939148   | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |             |\n",
            "| 0 | 822  | 12 | 6240 | 4469 | 0.11639762107051826 | 0.9856115107913669 | 0.20820668693009117 |  prefix  | string_exact | gradient  |  8.613692998886108  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |             |\n",
            "| 0 | 815  | 9  | 6268 | 4471 | 0.11506423831709728 | 0.9890776699029126 | 0.2061464525104338  |  prefix  | string_exact | gradient  |  8.997320890426636  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |             |\n",
            "| 0 | 4225 | 35 | 2834 | 4471 | 0.5985267034990792  | 0.9917840375586855 | 0.7465323791854405  |  qgram   |    qgram     |  prefix   |  71.67454814910889  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |      4      |\n",
            "| 0 | 4217 | 25 | 2836 | 4471 | 0.5979016021551113  | 0.9941065535124941 | 0.7467020805666225  |  qgram   |    qgram     |  prefix   |  74.8440408706665   | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |      4      |\n",
            "| 0 | 4211 | 23 | 2842 | 4471 | 0.5970509003261024  | 0.9945677846008503 | 0.7461681580579429  |  qgram   |    qgram     |  prefix   |  78.01111721992493  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |      4      |\n",
            "| 0 | 4200 | 23 | 2853 | 4471 | 0.5954912803062526  | 0.9945536348567369 | 0.7449450159631074  |  qgram   |    qgram     |  prefix   |  72.75200319290161  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |      4      |\n",
            "| 0 | 4191 | 26 | 2862 | 4471 | 0.5942152275627393  | 0.9938344794877876 | 0.7437444543034606  |  qgram   |    qgram     |  prefix   |  76.67781519889832  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |      4      |\n",
            "| 0 | 1130 | 70 | 6093 | 4468 | 0.1564446905717846  | 0.9416666666666667 | 0.26831295262970434 |  qgram   |    qgram     | gradient  |  75.03897094726562  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |      4      |\n",
            "| 0 | 1130 | 70 | 6093 | 4468 | 0.1564446905717846  | 0.9416666666666667 | 0.26831295262970434 |  qgram   |    qgram     | gradient  |  76.22497892379761  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |      4      |\n",
            "| 0 | 1130 | 70 | 6093 | 4468 | 0.1564446905717846  | 0.9416666666666667 | 0.26831295262970434 |  qgram   |    qgram     | gradient  |  82.4908037185669   | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |      4      |\n",
            "| 0 | 1130 | 70 | 6093 | 4468 | 0.1564446905717846  | 0.9416666666666667 | 0.26831295262970434 |  qgram   |    qgram     | gradient  |  86.19205403327942  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |      4      |\n",
            "| 0 | 1130 | 70 | 6093 | 4468 | 0.1564446905717846  | 0.9416666666666667 | 0.26831295262970434 |  qgram   |    qgram     | gradient  |  81.23690176010132  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |      4      |\n",
            "| 0 | 4229 | 38 | 2838 | 4467 | 0.5984151690957974  | 0.991094445746426  | 0.7462502205752602  |  qgram   | string_exact |  prefix   |  92.9336040019989   | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |      4      |\n",
            "| 0 | 4229 | 38 | 2838 | 4467 | 0.5984151690957974  | 0.991094445746426  | 0.7462502205752602  |  qgram   | string_exact |  prefix   |  91.06035256385803  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |      4      |\n",
            "| 0 | 4229 | 38 | 2838 | 4467 | 0.5984151690957974  | 0.991094445746426  | 0.7462502205752602  |  qgram   | string_exact |  prefix   |  90.93670177459717  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |      4      |\n",
            "| 0 | 4229 | 38 | 2838 | 4467 | 0.5984151690957974  | 0.991094445746426  | 0.7462502205752602  |  qgram   | string_exact |  prefix   |  97.11259436607361  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |      4      |\n",
            "| 0 | 4229 | 38 | 2838 | 4467 | 0.5984151690957974  | 0.991094445746426  | 0.7462502205752602  |  qgram   | string_exact |  prefix   |  94.89846658706665  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |      4      |\n",
            "| 0 | 1102 | 72 | 6111 | 4465 | 0.1527797033134618  | 0.938671209540034  | 0.2627876475497794  |  qgram   | string_exact | gradient  |  97.2102677822113   | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      3       |      4      |\n",
            "| 0 | 1120 | 70 | 6102 | 4468 | 0.15508169482137912 | 0.9411764705882353 | 0.2662862577270566  |  qgram   | string_exact | gradient  |  95.64522361755371  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      4       |      4      |\n",
            "| 0 | 1086 | 60 | 6135 | 4470 | 0.1503946821769838  | 0.9476439790575916 | 0.2595912513445679  |  qgram   | string_exact | gradient  |  88.79961943626404  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      5       |      4      |\n",
            "| 0 | 1042 | 69 | 6199 | 4468 | 0.1439027758596879  | 0.9378937893789379 | 0.24952107279693492 |  qgram   | string_exact | gradient  |  93.10746121406555  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      6       |      4      |\n",
            "| 0 | 996  | 81 | 6243 | 4466 | 0.13758806464981352 | 0.924791086350975  | 0.23953823953823955 |  qgram   | string_exact | gradient  |  94.89785885810852  | /content/gdrive/MyDrive/Colab Notebooks/Data Inputs/music_brainz_20k/ |      7       |      4      |\n",
            "+---+------+----+------+------+---------------------+--------------------+---------------------+----------+--------------+-----------+---------------------+-----------------------------------------------------------------------+--------------+-------------+\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from pathlib import Path\n",
        "import json\n",
        "import recordlinkage\n",
        "from tabulate import tabulate\n",
        "from recordlinkage.base import BaseCompareFeature\n",
        "from recordlinkage.index import BaseIndexAlgorithm\n",
        "import os\n",
        "import warnings\n",
        "import pprint\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from py_stringmatching import QgramTokenizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import re\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/Colab Notebooks\"\n",
        "voter_columns = [\"givenname\", \"surname\", \"postcode\", \"suburb\"]\n",
        "music_columns = [\"album\",\"artist\",\"title\"]\n",
        "geo_columns = [\"name\",\"longitude\",\"latitude\"]\n",
        "exact_string_match = [\"levenshtein\", \"damerau_levenshtein\", \"smith_waterman\", \"lcs\", \"qgram\"]\n",
        "path_voters = path+\"/Data Inputs/10Party-ocp20/\"\n",
        "path_music = path+\"/Data Inputs/music_brainz_20k/\"\n",
        "path_product = path +\"/Data Inputs/Amazon-GoogleProducts/\"\n",
        "dataset_list = {\n",
        "    # path_voters: path+\"/Data Outputs/Voters_Blocking_Comparisions.csv\",\n",
        "    path_music: path+\"/Data Outputs/Music_Blocking_Comparisions.csv\",\n",
        "    # path_product: path+\"/Data Outputs/Products_Blocking_Comparisions.csv\"\n",
        "}\n",
        "classification = [\"prefix\", \"gradient\"]\n",
        "threshold = 0.45\n",
        "qgram_block_threshold=0.8\n",
        "frac_data = 0.001\n",
        "bk = 3\n",
        "qgram_bk = 3\n",
        "num_music = 20000\n",
        "num_voter = 5000\n",
        "num_dup = 1000\n",
        "num_not_dup = 1000\n",
        "num_files = 1\n",
        "current_output = None\n",
        "columns = None\n",
        "\n",
        "def read_files(input_file_path):\n",
        "    global columns\n",
        "    lst_df = []\n",
        "    count = 0\n",
        "    for file in os.listdir(input_file_path):\n",
        "        if input_file_path == path_voters:\n",
        "            columns = voter_columns\n",
        "        elif input_file_path == path_music:\n",
        "            columns = music_columns\n",
        "        if count <= num_files:\n",
        "            df = pd.read_csv(input_file_path + file,encoding = 'UTF-8') # ISO-8859-1/UTF-8\n",
        "            lst_df.append(df)\n",
        "        count += 1\n",
        "    total_df = pd.concat(lst_df)[[\"recid\"] + columns]\n",
        "    total_df = total_df.sort_values(by=[\"recid\"])\n",
        "    total_df.dropna(inplace=True)\n",
        "    total_df.reset_index(drop=True, inplace=True)\n",
        "    if input_file_path == path_voters:\n",
        "        total_df[\"postcode\"] = total_df[\"postcode\"].astype(str)\n",
        "\n",
        "    # Default pick\n",
        "    if input_file_path==path_music:\n",
        "        short_df = total_df[:num_music]\n",
        "        short_df = short_df.apply(lambda x: x.astype(str).str.lower())\n",
        "        chars = re.escape(string.punctuation)\n",
        "        short_df[\"album\"] = short_df[\"album\"].apply(lambda x: re.sub(' +', ' ', re.sub(r'['+chars+']', ' ',x)))\n",
        "        short_df[\"artist\"] = short_df[\"artist\"].apply(lambda x: re.sub(' +', ' ', re.sub(r'['+chars+']', ' ',x)))\n",
        "        short_df[\"title\"] = short_df[\"title\"].apply(lambda x: re.sub(' +', ' ', re.sub(r'['+chars+']', ' ',x)))\n",
        "    else:\n",
        "        short_df = total_df[:num_voter]\n",
        "    # short_df = total_df.sample(frac=frac_data, random_state=1)\n",
        "\n",
        "    # Manual pick\n",
        "    # dup_df = total_df[total_df[\"recid\"].duplicated(keep=False)].sort_values(by=[\"recid\"])\n",
        "    # non_dup_df = total_df[~total_df[\"recid\"].duplicated(keep=False)]\n",
        "    # short_df = pd.concat([dup_df[:num_dup], non_dup_df[:num_not_dup]])\n",
        "    return short_df\n",
        "\n",
        "# Block\n",
        "def generate_qgram(data):\n",
        "    temp= []\n",
        "    def combinationUtil(arr, data, start,end, index, r):\n",
        "        if (index == r):\n",
        "            temp.append([data[j] for j in range(r)])\n",
        "            return\n",
        "        i = start\n",
        "\n",
        "        while (i <= end and end - i + 1 >= r - index):\n",
        "            data[index] = arr[i]\n",
        "            combinationUtil(arr, data, i + 1,end, index + 1, r)\n",
        "            i += 1\n",
        "\n",
        "    import math\n",
        "    q_tokenized = QgramTokenizer(qval=qgram_bk, padding=False).tokenize(data)\n",
        "    length_sublist = math.floor(len(q_tokenized)*qgram_block_threshold)\n",
        "    n = len(q_tokenized)\n",
        "    while length_sublist <= len(q_tokenized):\n",
        "        data = [0] * length_sublist\n",
        "        combinationUtil(q_tokenized, data, 0, n - 1, 0, length_sublist)\n",
        "        length_sublist+=1\n",
        "    return list(set([\"\".join(i) for i in temp]))\n",
        "\n",
        "def insert_values_k_v(row,diff_key,col):\n",
        "    for term in row[col]:\n",
        "        if len(diff_key[term])==0:\n",
        "            diff_key[term]=[row[\"index\"]]\n",
        "        else:\n",
        "            diff_key[term].append(row[\"index\"])\n",
        "    return row\n",
        "\n",
        "def convet_multindex(row):\n",
        "    v = row[\"values\"]\n",
        "    np_lst = np.asarray(v)\n",
        "    levels = [np_lst, np_lst]\n",
        "    codes = np.tril_indices(len(np_lst), k=-1)\n",
        "    multi_index = pd.MultiIndex(levels=levels,\n",
        "                     codes=codes,\n",
        "                     verify_integrity=False)\n",
        "    multi_index_ls = multi_index.tolist()\n",
        "    return multi_index_ls\n",
        "\n",
        "class BlockQgram(BaseIndexAlgorithm):\n",
        "\n",
        "    def _dedup_index(self, df_a):\n",
        "        # if not os.path.exists(current_output):\n",
        "        col = self.verify_integrity\n",
        "        diff_table = list(set(sum(df_a[col].drop_duplicates().tolist(),[])))\n",
        "        diff_key = dict.fromkeys(diff_table,[])\n",
        "        df_a[\"index\"] = df_a.index\n",
        "        df_a = df_a.apply(lambda x:insert_values_k_v(x,diff_key,col),axis=1)\n",
        "        diff_key_df =pd.DataFrame(list(diff_key.items()))\n",
        "        diff_key_df.columns=[\"blocking keys\",\"values\"]\n",
        "        diff_key_df = diff_key_df[diff_key_df[\"values\"].str.len()>=2]\n",
        "        diff_key_df[\"multi_index\"] = diff_key_df.apply(lambda x: convet_multindex(x),axis=1)\n",
        "        multindex_joined = diff_key_df[\"multi_index\"].sum()\n",
        "        multindex_joined = list(set(multindex_joined))\n",
        "        results =  pd.MultiIndex.from_frame(pd.DataFrame(multindex_joined).sort_values([0]))\n",
        "        temp_result_block = results.to_frame().reset_index(drop=True)\n",
        "        temp_result_block.to_csv(current_output,index=False)\n",
        "        # else:\n",
        "        #     data = pd.read_csv(current_output)\n",
        "        #     results = pd.MultiIndex.from_frame(data)\n",
        "        return results\n",
        "\n",
        "# Comparision\n",
        "class CompareLevenshtein(BaseCompareFeature):\n",
        "\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        conc = pd.Series(list(zip(s1, s2)))\n",
        "\n",
        "        from jellyfish import levenshtein_distance\n",
        "\n",
        "        def levenshtein_apply(x):\n",
        "\n",
        "            try:\n",
        "                return 1 - levenshtein_distance(x[0], x[1]) \\\n",
        "                       / np.max([len(x[0]), len(x[1])])\n",
        "            except Exception as err:\n",
        "                if pd.isnull(x[0]) or pd.isnull(x[1]):\n",
        "                    return np.nan\n",
        "                else:\n",
        "                    raise err\n",
        "\n",
        "        return conc.apply(levenshtein_apply)\n",
        "\n",
        "class CompareDamerauLevenshtein(BaseCompareFeature):\n",
        "\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        conc = pd.Series(list(zip(s1, s2)))\n",
        "\n",
        "        from jellyfish import damerau_levenshtein_distance\n",
        "\n",
        "        def damerau_levenshtein_apply(x):\n",
        "\n",
        "            try:\n",
        "                return 1 - damerau_levenshtein_distance(x[0], x[1]) \\\n",
        "                       / np.max([len(x[0]), len(x[1])])\n",
        "            except Exception as err:\n",
        "                if pd.isnull(x[0]) or pd.isnull(x[1]):\n",
        "                    return np.nan\n",
        "                else:\n",
        "                    raise err\n",
        "\n",
        "        return conc.apply(damerau_levenshtein_apply)\n",
        "\n",
        "class CompareSmithWaterman(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        match = 5\n",
        "        mismatch = -5\n",
        "        gap_start = -5\n",
        "        gap_continue = -1\n",
        "        norm = \"mean\"\n",
        "        assert match >= max(mismatch, gap_start, gap_continue), \\\n",
        "            \"match must be greater than or equal to mismatch, \" \\\n",
        "            \"gap_start, and gap_continue\"\n",
        "\n",
        "        if len(s1) != len(s2):\n",
        "            raise ValueError('Arrays or Series have to be same length.')\n",
        "\n",
        "        if len(s1) == len(s2) == 0:\n",
        "            return []\n",
        "\n",
        "        concat = pd.Series(list(zip(s1, s2)))\n",
        "\n",
        "        def sw_apply(t):\n",
        "            str1 = t[0]\n",
        "            str2 = t[1]\n",
        "\n",
        "            def compute_score():\n",
        "                m = [[0] * (1 + len(str2)) for i in range(1 + len(str1))]\n",
        "\n",
        "                # Initialize the trace matrix with empty lists\n",
        "                trace = [[[] for _ in range(1 + len(str2))]\n",
        "                         for _ in range(1 + len(str1))]\n",
        "\n",
        "                # Initialize the highest seen score to 0\n",
        "                highest = 0\n",
        "\n",
        "                # Iterate through the matrix\n",
        "                for x in range(1, 1 + len(str1)):\n",
        "                    for y in range(1, 1 + len(str2)):\n",
        "                        # Calculate Diagonal Score\n",
        "                        if str1[x - 1] == str2[y - 1]:\n",
        "                            # If characters match, add the match score to the\n",
        "                            # diagonal score\n",
        "                            diagonal = m[x - 1][y - 1] + match\n",
        "                        else:\n",
        "                            # If characters do not match, add the mismatch score\n",
        "                            # to the diagonal score\n",
        "                            diagonal = m[x - 1][y - 1] + mismatch\n",
        "\n",
        "                        # Calculate the Left Gap Score\n",
        "                        if \"H\" in trace[x - 1][y]:\n",
        "                            # If cell to the left's score was calculated based on\n",
        "                            # a horizontal gap, add the gap continuation penalty\n",
        "                            # to the left score.\n",
        "                            gap_horizontal = m[x - 1][y] + gap_continue\n",
        "                        else:\n",
        "                            # Otherwise, add the gap start penalty to the left\n",
        "                            # score\n",
        "                            gap_horizontal = m[x - 1][y] + gap_start\n",
        "\n",
        "                        # Calculate the Above Gap Score\n",
        "                        if \"V\" in trace[x][y - 1]:\n",
        "                            # If above cell's score was calculated based on a\n",
        "                            # vertical gap, add the gap continuation penalty to\n",
        "                            # the above score.\n",
        "                            gap_vertical = m[x][y - 1] + gap_continue\n",
        "                        else:\n",
        "                            # Otherwise, add the gap start penalty to the above\n",
        "                            # score\n",
        "                            gap_vertical = m[x][y - 1] + gap_start\n",
        "\n",
        "                        # Choose the highest of the three scores\n",
        "                        score = max(diagonal, gap_horizontal, gap_vertical)\n",
        "\n",
        "                        if score <= 0:\n",
        "                            # If score is less than 0, boost to 0\n",
        "                            score = 0\n",
        "                        else:\n",
        "                            # If score is greater than 0, determine whether it was\n",
        "                            # calculated based on a diagonal score, horizontal gap,\n",
        "                            # or vertical gap. Store D, H, or V in the trace matrix\n",
        "                            # accordingly.\n",
        "                            if score == diagonal:\n",
        "                                trace[x][y].append(\"D\")\n",
        "                            if score == gap_horizontal:\n",
        "                                trace[x][y].append(\"H\")\n",
        "                            if score == gap_vertical:\n",
        "                                trace[x][y].append(\"V\")\n",
        "\n",
        "                        # If the cell's score is greater than the highest score\n",
        "                        # previously present, record the score as the highest.\n",
        "                        if score > highest:\n",
        "                            highest = score\n",
        "\n",
        "                        # Set the cell's score to score\n",
        "                        m[x][y] = score\n",
        "\n",
        "                # After iterating through the entire matrix, return the highest\n",
        "                # score found.\n",
        "                return highest\n",
        "\n",
        "            def normalize(score):\n",
        "                if norm == \"min\":\n",
        "                    # Normalize by the shorter string's length\n",
        "                    return score / (min(len(str1), len(str2)) * match)\n",
        "                if norm == \"max\":\n",
        "                    # Normalize by the longer string's length\n",
        "                    return score / (max(len(str1), len(str2)) * match)\n",
        "                if norm == \"mean\":\n",
        "                    # Normalize by the mean length of the two strings\n",
        "                    return 2 * score / ((len(str1) + len(str2)) * match)\n",
        "                else:\n",
        "                    warnings.warn(\n",
        "                        'Unrecognized longest common substring normalization. '\n",
        "                        'Defaulting to \"mean\" method.')\n",
        "                    return 2 * score / ((len(str1) + len(str2)) * match)\n",
        "\n",
        "            try:\n",
        "                if len(str1) == 0 or len(str2) == 0:\n",
        "                    return 0\n",
        "                return normalize(compute_score())\n",
        "\n",
        "            except Exception as err:\n",
        "                if pd.isnull(t[0]) or pd.isnull(t[1]):\n",
        "                    return np.nan\n",
        "                else:\n",
        "                    raise err\n",
        "\n",
        "        return concat.apply(sw_apply)\n",
        "\n",
        "class CompareLCS(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "\n",
        "        norm = 'dice'\n",
        "        min_len = 2\n",
        "        if len(s1) != len(s2):\n",
        "            raise ValueError('Arrays or Series have to be same length.')\n",
        "\n",
        "        if len(s1) == len(s2) == 0:\n",
        "            return []\n",
        "\n",
        "        conc = pd.Series(list(zip(s1, s2)))\n",
        "\n",
        "        def lcs_iteration(x):\n",
        "\n",
        "            str1 = x[0]\n",
        "            str2 = x[1]\n",
        "\n",
        "            if str1 is np.nan or str2 is np.nan or min(len(str1),\n",
        "                                                       len(str2)) < min_len:\n",
        "                longest = 0\n",
        "                new_str1 = None\n",
        "                new_str2 = None\n",
        "            else:\n",
        "                # Creating a matrix of 0s for preprocessing\n",
        "                m = [[0] * (1 + len(str2)) for _ in range(1 + len(str1))]\n",
        "\n",
        "                # Track length of longest substring seen\n",
        "                longest = 0\n",
        "\n",
        "                # Track the ending position of this substring in str1 (x) and\n",
        "                # str2(y)\n",
        "                x_longest = 0\n",
        "                y_longest = 0\n",
        "\n",
        "                # Create matrix of substring lengths\n",
        "                for x in range(1, 1 + len(str1)):\n",
        "                    for y in range(1, 1 + len(str2)):\n",
        "                        # Check if the chars match\n",
        "                        if str1[x - 1] == str2[y - 1]:\n",
        "                            # add 1 to the diagonal\n",
        "                            m[x][y] = m[x - 1][y - 1] + 1\n",
        "                            # Update values if longer than previous longest\n",
        "                            # substring\n",
        "                            if m[x][y] > longest:\n",
        "                                longest = m[x][y]\n",
        "                                x_longest = x\n",
        "                                y_longest = y\n",
        "                        else:\n",
        "                            # If there is no match, start from zero\n",
        "                            m[x][y] = 0\n",
        "\n",
        "                # Copy str1 and str2, but subtract the longest common substring\n",
        "                # for the next iteration.\n",
        "                new_str1 = str1[0:x_longest - longest] + str1[x_longest:]\n",
        "                new_str2 = str2[0:y_longest - longest] + str2[y_longest:]\n",
        "\n",
        "            return (new_str1, new_str2), longest\n",
        "\n",
        "        def lcs_apply(x):\n",
        "            if pd.isnull(x[0]) or pd.isnull(x[1]):\n",
        "                return np.nan\n",
        "\n",
        "            # Compute lcs value with first ordering.\n",
        "            lcs_acc_1 = 0\n",
        "            new_x_1 = (x[0], x[1])\n",
        "            while True:\n",
        "                # Get new string pair (iter_x) and length (iter_lcs)\n",
        "                # for this iteration.\n",
        "                iter_x, iter_lcs = lcs_iteration(new_x_1)\n",
        "                if iter_lcs < min_len:\n",
        "                    # End if the longest substring is below the threshold\n",
        "                    break\n",
        "                else:\n",
        "                    # Otherwise, accumulate length and start a new iteration\n",
        "                    # with the new string pair.\n",
        "                    new_x_1 = iter_x\n",
        "                    lcs_acc_1 = lcs_acc_1 + iter_lcs\n",
        "\n",
        "            # Compute lcs value with second ordering.\n",
        "            lcs_acc_2 = 0\n",
        "            new_x_2 = (x[1], x[0])\n",
        "            while True:\n",
        "                # Get new string pair (iter_x) and length (iter_lcs)\n",
        "                # for this iteration.\n",
        "                iter_x, iter_lcs = lcs_iteration(new_x_2)\n",
        "                if iter_lcs < min_len:\n",
        "                    # End if the longest substring is below the threshold\n",
        "                    break\n",
        "                else:\n",
        "                    # Otherwise, accumulate length and start a new iteration\n",
        "                    # with the new string pair.\n",
        "                    new_x_2 = iter_x\n",
        "                    lcs_acc_2 = lcs_acc_2 + iter_lcs\n",
        "\n",
        "            def normalize_lcs(lcs_value):\n",
        "                if len(x[0]) == 0 or len(x[1]) == 0:\n",
        "                    return 0\n",
        "                if norm == 'overlap':\n",
        "                    return lcs_value / min(len(x[0]), len(x[1]))\n",
        "                elif norm == 'jaccard':\n",
        "                    return lcs_value / (len(x[0]) + len(x[1]) - abs(lcs_value))\n",
        "                elif norm == 'dice':\n",
        "                    return lcs_value * 2 / (len(x[0]) + len(x[1]))\n",
        "                else:\n",
        "                    warnings.warn(\n",
        "                        'Unrecognized longest common substring normalization. '\n",
        "                        'Defaulting to \"dice\" method.')\n",
        "                    return lcs_value * 2 / (len(x[0]) + len(x[1]))\n",
        "\n",
        "            # Average the two orderings, since lcs may be sensitive to comparison\n",
        "            # order.\n",
        "            return (normalize_lcs(lcs_acc_1) + normalize_lcs(lcs_acc_2)) / 2\n",
        "\n",
        "        return conc.apply(lcs_apply)\n",
        "\n",
        "class CompareTrigram(BaseCompareFeature):\n",
        "\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        if len(s1) == len(s2) == 0:\n",
        "            return np.empty(0)\n",
        "        data = pd.concat([s1, s2]).fillna('')\n",
        "        vectorizer = CountVectorizer(analyzer=\"char\",\n",
        "                                     strip_accents='unicode',\n",
        "                                     ngram_range=(bk, bk))\n",
        "        vec_fit = vectorizer.fit_transform(data)\n",
        "\n",
        "        def _metric_sparse_euclidean(u, v):\n",
        "            match_ngrams = u.minimum(v).sum(axis=1)\n",
        "            total_ngrams = np.maximum(u.sum(axis=1), v.sum(axis=1))\n",
        "\n",
        "            # division by zero is not possible in our case, but 0/0 is possible.\n",
        "            # Numpy raises a warning in that case.\n",
        "\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                m = np.true_divide(match_ngrams, total_ngrams).A1\n",
        "            return m\n",
        "\n",
        "        value = _metric_sparse_euclidean(vec_fit[:len(s1)], vec_fit[len(s1):])\n",
        "        return value\n",
        "\n",
        "class CompareCosin(BaseCompareFeature):\n",
        "    def _compute_vectorized(self, s1, s2):\n",
        "        include_wb = True\n",
        "        ngram = (bk, bk)\n",
        "        if len(s1) != len(s2):\n",
        "            raise ValueError('Arrays or Series have to be same length.')\n",
        "\n",
        "        if len(s1) == len(s2) == 0:\n",
        "            return []\n",
        "\n",
        "        # include word boundaries or not\n",
        "        analyzer = 'char_wb' if include_wb is True else 'char'\n",
        "\n",
        "        # The vectorizer\n",
        "        vectorizer = CountVectorizer(analyzer=analyzer,\n",
        "                                     strip_accents='unicode',\n",
        "                                     ngram_range=ngram)\n",
        "\n",
        "        data = pd.concat([s1, s2]).fillna('')\n",
        "\n",
        "        vec_fit = vectorizer.fit_transform(data)\n",
        "\n",
        "        def _metric_sparse_cosine(u, v):\n",
        "\n",
        "            a = np.sqrt(u.multiply(u).sum(axis=1))\n",
        "            b = np.sqrt(v.multiply(v).sum(axis=1))\n",
        "\n",
        "            ab = v.multiply(u).sum(axis=1)\n",
        "\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\")\n",
        "                m = np.divide(ab, np.multiply(a, b)).A1\n",
        "\n",
        "            return m\n",
        "\n",
        "        return _metric_sparse_cosine(vec_fit[:len(s1)], vec_fit[len(s1):])\n",
        "\n",
        "# Clasification\n",
        "# Kmeans not working well\n",
        "def kmeans_process(features,df):\n",
        "    features = features.dropna()\n",
        "    split_index_features = features.reset_index()\n",
        "    split_index_features[\"match\"] = split_index_features[[\"level_0\", \"level_1\"]].apply(\n",
        "        lambda x: df.loc[x[\"level_0\"], \"recid\"] == df.loc[x[\"level_1\"], \"recid\"], axis=1)\n",
        "    split_index_features[\"match\"] = split_index_features[\"match\"].apply(lambda x: 1 if x == True else 0)\n",
        "    train,test = train_test_split(\n",
        "        split_index_features[[i for i in split_index_features.columns if i not in [\"match\"]]], random_state=100,\n",
        "        test_size=0.2)\n",
        "    # drop_index_train = train.drop(columns=[\"level_0\", \"level_1\"]).reset_index(drop=True)\n",
        "    # drop_index_test = test.drop(columns=[\"level_0\", \"level_1\"]).reset_index(drop=True)\n",
        "    # kmeans = recordlinkage.KMeansClassifier()\n",
        "    # result_kmeans = kmeans.learn(drop_index_train)\n",
        "    # predictions = kmeans.predict(drop_index_test)\n",
        "    # test[\"match\"] = predictions\n",
        "\n",
        "    # pca = PCA(2)\n",
        "    # df = pca.fit_transform(split_index_features[[i for i in split_index_features.columns if i not in [\"match\"]]])\n",
        "    kmeans = KMeans(n_clusters=2)\n",
        "    label = kmeans.fit_predict(split_index_features[[i for i in split_index_features.columns if i not in [\"match\"]]])\n",
        "    # Getting unique labels\n",
        "\n",
        "    u_labels = np.unique(label)\n",
        "\n",
        "    # plotting the results:\n",
        "\n",
        "    for i in u_labels:\n",
        "        plt.scatter(df[label == i, 0], df[label == i, 1], label=i)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Getting the Centroids\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    u_labels = np.unique(label)\n",
        "\n",
        "    # plotting the results:\n",
        "\n",
        "    for i in u_labels:\n",
        "        plt.scatter(df[label == i, 0], df[label == i, 1], label=i)\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1], s=80, color='k')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return test\n",
        "\n",
        "def classi_gradient(features,df):\n",
        "    features = features.dropna()\n",
        "    split_index_features = features.reset_index()\n",
        "    split_index_features[\"match\"] = split_index_features[[\"level_0\", \"level_1\"]].apply(\n",
        "        lambda x: df.loc[x[\"level_0\"], \"recid\"] == df.loc[x[\"level_1\"], \"recid\"], axis=1)\n",
        "    split_index_features[\"match\"] = split_index_features[\"match\"].apply(lambda x: 1 if x == True else 0)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(split_index_features[[i for i in split_index_features.columns if i not in [\"match\"]]],split_index_features[\"match\"], random_state=100,test_size=0.2)\n",
        "    drop_index_X_train = X_train.drop(columns=[\"level_0\", \"level_1\"]).reset_index(drop=True)\n",
        "    drop_index_X_test = X_test.drop(columns=[\"level_0\", \"level_1\"]).reset_index(drop=True)\n",
        "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000)\n",
        "    clf.fit(drop_index_X_train, y_train)\n",
        "    predicted = clf.predict(drop_index_X_test)\n",
        "    weights = clf.coef_\n",
        "    bias = clf.intercept_\n",
        "    matches = predicted\n",
        "    X_test[\"match\"] = matches\n",
        "    return X_test\n",
        "\n",
        "def process_record_linkage(input_file_path,outputs,short_df, block_algo, match_algo, classi):\n",
        "    global current_output\n",
        "    df = short_df\n",
        "    indexer = recordlinkage.Index()\n",
        "    if block_algo == \"prefix\":\n",
        "        # Block generation for trigram\n",
        "        if input_file_path == path_voters:\n",
        "            df[\"gn_prefix\"] = df[\"givenname\"].str[:3]\n",
        "            df[\"sn_prefix\"] = df[\"surname\"].str[:3]\n",
        "            indexer.block([\"sn_prefix\", \"gn_prefix\"])\n",
        "        elif input_file_path == path_music:\n",
        "            df[\"at_artist\"] = df[\"artist\"].str[:3]\n",
        "            df[\"tt_title\"] = df[\"title\"].str[:3]\n",
        "            df[\"ab_album\"] = df[\"album\"].str[:3]\n",
        "            indexer.block([\"at_artist\", \"tt_title\",\"ab_album\"])\n",
        "    elif block_algo == \"qgram\":\n",
        "        current_output = outputs\n",
        "        # if not os.path.exists(current_output):\n",
        "        if input_file_path == path_voters:\n",
        "            df[\"joined_col\"] = df[\"givenname\"] + \" \" + df[\"surname\"]\n",
        "        elif input_file_path == path_music:\n",
        "            df[\"joined_col\"] = df[\"at_artist\"] + \" \" + df[\"tt_title\"]+ \" \" + df[\"ab_album\"]\n",
        "        df[\"joined_qgram\"]= df[\"joined_col\"].apply(lambda x: generate_qgram(x))\n",
        "        indexer.add(BlockQgram(\"joined_qgram\"))\n",
        "    # elif block_algo == \"sorted\":\n",
        "    #     indexer = recordlinkage.SortedNeighbourhoodIndex(on=\"givenname\",window=3)\n",
        "    candidate_links = indexer.index(df)\n",
        "\n",
        "    # Comparing\n",
        "    compare_cl = recordlinkage.Compare()\n",
        "    if match_algo == \"string_exact\":\n",
        "        for column in columns:\n",
        "            exact_string_match = [\"levenshtein\", \"damerau_levenshtein\", \"smith_waterman\", \"lcs\", \"qgram\",\"cosin\"]\n",
        "            for method in exact_string_match:\n",
        "                # compare_cl.string(column, column, method=method, threshold=threshold,\n",
        "                #                   label=method + \"_\" + column + \"_sc\")\n",
        "                if method == \"levenshtein\":\n",
        "                    compare_cl.add(CompareLevenshtein(column, column, label= method + \"_\" + column + \"_sc\"))\n",
        "                elif method == \"damerau_levenshtein\":\n",
        "                    compare_cl.add(CompareDamerauLevenshtein(column, column, label= method + \"_\" + column + \"_sc\"))\n",
        "                elif method == \"smith_waterman\":\n",
        "                    compare_cl.add(CompareSmithWaterman(column, column, label= method + \"_\" + column + \"_sc\"))\n",
        "                elif method == \"lcs\":\n",
        "                    compare_cl.add(CompareLCS(column, column, label= method + \"_\" + column + \"_sc\"))\n",
        "                elif method==\"qgram\":\n",
        "                    compare_cl.add(CompareTrigram(column, column, label=method + \"_\" + column + \"_sc\"))\n",
        "    elif match_algo == \"qgram\":\n",
        "        for column in columns:\n",
        "            if input_file_path == path_music:\n",
        "                compare_cl.add(CompareCosin(column, column, label=column + \"_sc\"))\n",
        "            else:\n",
        "                compare_cl.add(CompareTrigram(column, column, label=column + \"_sc\"))\n",
        "\n",
        "    features = compare_cl.compute(candidate_links, df)\n",
        "    print(len(candidate_links))\n",
        "    # Classification\n",
        "    if classi == \"prefix\":\n",
        "        sc_col = [col for col in features.columns if \"_sc\" in col]\n",
        "        features[\"aver\"] = features[sc_col].sum(axis=1)/len(sc_col)\n",
        "        matches = features[features[\"aver\"] >= threshold]\n",
        "        return matches,df\n",
        "    elif classi == \"gradient\":\n",
        "        # 2 models\n",
        "        features_diff_method = features\n",
        "        X_test_diff_method = classi_gradient(features_diff_method,df)\n",
        "        return X_test_diff_method,df\n",
        "    elif classi == \"unsupervised\":\n",
        "        matches= kmeans_process(features,df)\n",
        "        return matches,df\n",
        "\n",
        "def display_data(matches, df):\n",
        "    # Display the data\n",
        "    matches.reset_index(inplace=True)\n",
        "    matches = matches.rename(columns={'level_0': 'df1_index', 'level_1': 'df2_index'})\n",
        "    new_col = [\"gn_1\", \"gn_2\", \"sn_1\", \"sn_2\", \"pc_1\", \"pc_2\", \"sb_1\", \"sb_2\"]\n",
        "    for col in new_col:\n",
        "        if col in [\"gn_1\", \"gn_2\"]:\n",
        "            correct_col = \"givenname\"\n",
        "        elif col in [\"sn_1\", \"sn_2\"]:\n",
        "            correct_col = \"surname\"\n",
        "        elif col in [\"pc_1\", \"pc_2\"]:\n",
        "            correct_col = \"postcode\"\n",
        "        else:\n",
        "            correct_col = \"postcode\"\n",
        "        if \"1\" in col:\n",
        "            matches[col] = df[correct_col][matches[\"df1_index\"]].reset_index(drop=True)\n",
        "        else:\n",
        "            matches[col] = df[correct_col][matches[\"df2_index\"]].reset_index(drop=True)\n",
        "    cleaned_matches = matches[\n",
        "        [\"df1_index\", \"df2_index\", \"gn_1\", \"gn_2\", \"givenname_sc\", \"sn_1\", \"sn_2\", \"surname_sc\", \"pc_1\", \"pc_2\",\n",
        "         \"postcode_sc\", \"sb_1\", \"sb_2\", \"suburb_sc\"]]\n",
        "    return cleaned_matches\n",
        "\n",
        "def evaluation_process(matches, ref_df):\n",
        "    # Get the original matched values and non-matched values\n",
        "    non_match_ori_df = ref_df[ref_df[\"recid\"].duplicated(keep=False) == False]\n",
        "    match_ori_df = ref_df[ref_df[\"recid\"].duplicated(keep=False)]\n",
        "\n",
        "    # Calculate if the predicted values are correct or not\n",
        "    predicted_matches_df1 = ref_df.loc[matches[\"df1_index\"].tolist()]\n",
        "    predicted_matches_df2 = ref_df.loc[matches[\"df2_index\"].tolist()]\n",
        "    predicted_non_match_df = ref_df[(~ref_df[\"recid\"].isin(predicted_matches_df1[\"recid\"].tolist())) | (\n",
        "        ~ref_df[\"recid\"].isin(predicted_matches_df2[\"recid\"].tolist()))]\n",
        "    predicted_match_df = ref_df[(ref_df[\"recid\"].isin(predicted_matches_df1[\"recid\"].tolist())) | (\n",
        "        ref_df[\"recid\"].isin(predicted_matches_df2[\"recid\"].tolist()))]\n",
        "    values = (predicted_matches_df1.reset_index(drop=True)[\"recid\"] == predicted_matches_df2.reset_index(drop=True)[\n",
        "        \"recid\"]).value_counts()\n",
        "    TP = len(list(set(predicted_match_df.index.tolist()) & set(match_ori_df.index.tolist())))\n",
        "    TN = len(list(set(predicted_non_match_df.index.tolist()) & set(non_match_ori_df.index.tolist())))\n",
        "    FN = len(set(predicted_match_df.index.tolist()) & set(non_match_ori_df.index.tolist()))\n",
        "    FP = len(set(predicted_non_match_df.index.tolist()) & set(match_ori_df.index.tolist()))\n",
        "\n",
        "    # Calculate F1, recall, precision\n",
        "    precision = TP / (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "    F1 = 2 * (recall * precision) / (recall + precision)\n",
        "    metrics = dict(\n",
        "        TP=TP,\n",
        "        FN=FN,\n",
        "        FP=FP,\n",
        "        TN=TN,\n",
        "        precision=precision,\n",
        "        recall=recall,\n",
        "        F1=F1,\n",
        "    )\n",
        "    print(\"Metrics:\")\n",
        "    pprint.pprint(metrics)\n",
        "    return metrics\n",
        "\n",
        "def main():\n",
        "    # block_al: qgram / prefix\n",
        "    # match_algo: string_exact / qgram\n",
        "    # classi: gradient / prefix\n",
        "\n",
        "    # process_order: block - match_algo - classi\n",
        "    #[\"prefix\", \"string_exact\", \"unsupervised\"],\n",
        "    process_order = [\n",
        "                     [\"prefix\",\"qgram\",\"prefix\"],\n",
        "                     [\"prefix\", \"qgram\", \"gradient\"],\n",
        "                     [\"prefix\", \"string_exact\", \"prefix\"],\n",
        "                     [\"prefix\",\"string_exact\",\"gradient\"],\n",
        "                    [\"qgram\", \"qgram\", \"prefix\"],\n",
        "                     [\"qgram\", \"qgram\", \"gradient\"],\n",
        "                     [\"qgram\", \"string_exact\", \"prefix\"],\n",
        "                     [\"qgram\",\"string_exact\",\"gradient\"],\n",
        "                     ]\n",
        "\n",
        "    metrics = []\n",
        "    global bk\n",
        "    global qgram_bk\n",
        "    for dataset,outputs in dataset_list.items():\n",
        "        short_df = read_files(dataset)\n",
        "        for case in process_order:\n",
        "            bk = 3\n",
        "            for bl_key in range(bk,8):\n",
        "              bk = bl_key\n",
        "              print(\"BK\",bk)\n",
        "              # for block_al in block_algo_list:\n",
        "              # if case[0]==\"prefix\":\n",
        "              block_al = case[0]\n",
        "              match_algo = case[1]\n",
        "              classi = case[2]\n",
        "              if block_al == \"qgram\":\n",
        "                  qgram_bk=3\n",
        "                  for key_block in range(qgram_bk,5):\n",
        "                    qgram_bk = key_block\n",
        "                    print(\"Qgram_BK\",qgram_bk)\n",
        "                    start = time.time()\n",
        "                    if match_algo == \"qgram\":\n",
        "                        matches, df = process_record_linkage(dataset,outputs,short_df, block_al, match_algo, classi)\n",
        "                        # matches = display_data(matches, df)\n",
        "                        matches.reset_index(inplace=True)\n",
        "                        matches.rename(columns={'level_0': 'df1_index', 'level_1': 'df2_index'}, inplace=True)\n",
        "                        print(case[0],case[1],case[2],\"match:\")\n",
        "                        metric = evaluation_process(matches, short_df)\n",
        "                    elif match_algo == \"string_exact\":\n",
        "                        matches, df = process_record_linkage(dataset,outputs,short_df, block_al, match_algo, classi)\n",
        "                        # cleaned_matches = display_data(matches, df)\n",
        "                        matches.reset_index(inplace=True)\n",
        "                        matches.rename(columns={'level_0': 'df1_index', 'level_1': 'df2_index'},inplace=True)\n",
        "                        print(case[0],case[1],case[2],\"match:\")\n",
        "                        metric = evaluation_process(matches, short_df)\n",
        "                    end = time.time()\n",
        "              else:\n",
        "                  start = time.time()\n",
        "                  if match_algo == \"qgram\":\n",
        "                      matches, df = process_record_linkage(dataset,outputs,short_df, block_al, match_algo, classi)\n",
        "                      # matches = display_data(matches, df)\n",
        "                      matches.reset_index(inplace=True)\n",
        "                      matches.rename(columns={'level_0': 'df1_index', 'level_1': 'df2_index'}, inplace=True)\n",
        "                      print(case[0],case[1],case[2],\"match:\")\n",
        "                      metric = evaluation_process(matches, short_df)\n",
        "                  elif match_algo == \"string_exact\":\n",
        "                      matches, df = process_record_linkage(dataset,outputs,short_df, block_al, match_algo, classi)\n",
        "                      # cleaned_matches = display_data(matches, df)\n",
        "                      matches.reset_index(inplace=True)\n",
        "                      matches.rename(columns={'level_0': 'df1_index', 'level_1': 'df2_index'},inplace=True)\n",
        "                      print(case[0],case[1],case[2],\"match:\")\n",
        "                      metric = evaluation_process(matches, short_df)\n",
        "                  end = time.time()\n",
        "              total_time = end - start\n",
        "              print(total_time)\n",
        "              metric[\"Block_Al\"] = block_al\n",
        "              metric[\"Match_Al\"] = match_algo\n",
        "              metric[\"Classi_Al\"] = classi\n",
        "              metric[\"Duration\"] = total_time\n",
        "              metric[\"Dataset\"] = dataset\n",
        "              metric[\"Blocking Key\"]=bl_key\n",
        "              if block_al==\"qgram\":\n",
        "                  metric[\"Block_Qgram\"]=qgram_bk\n",
        "              else:\n",
        "                  metric[\"Block_Qgram\"]=\"\"\n",
        "              metric_df = pd.DataFrame.from_dict([metric])\n",
        "              metrics.append(metric_df)\n",
        "    metrics_df = pd.concat(metrics)\n",
        "    print(tabulate(metrics_df, headers=metrics_df.columns.tolist(), tablefmt=\"pretty\"))\n",
        "    metrics_df.to_csv(\"Benchmar_ER.csv\",index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYRdiDf-U8-C"
      },
      "outputs": [],
      "source": [
        " # from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ-gVaNXWM3p"
      },
      "outputs": [],
      "source": [
        "# music_result = pd.read_csv(path+\"/Data Outputs/music.csv\")\n",
        "# voter_result = pd.read_csv(path+\"/Data Outputs/voter.csv\")\n",
        "# music_result[\"data\"]=\"music\"\n",
        "# voter_result[\"data\"]=\"voter\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoyzRV8r76JF"
      },
      "outputs": [],
      "source": [
        "# import seaborn as sns\n",
        "\n",
        "# joined_df = pd.concat([music_result,voter_result]).sort_values(by=[\"Methods\",\"data\"]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVx-YIY88JuL"
      },
      "outputs": [],
      "source": [
        "# from matplotlib.pyplot import figure\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# bx = voter_result.plot(x='Methods',figsize=(10,5),\n",
        "#         kind='bar',\n",
        "#         stacked=False,\n",
        "#         )\n",
        "\n",
        "# bx.set_xlabel(\"List of methods for Person domain\")\n",
        "# bx.set_ylabel(\"Percent\")\n",
        "# fig = bx.get_figure()\n",
        "# fig.savefig(path+\"/Data Outputs/bar_person.png\",bbox_inches='tight')\n",
        "\n",
        "# ax = music_result.plot(x='Methods',figsize=(10,5),\n",
        "#         kind='bar',\n",
        "#         stacked=False,\n",
        "#        )\n",
        "# ax.set_ylabel(\"Percent\")\n",
        "# ax.set_xlabel(\"List of methods for Music domain\")\n",
        "# fig2 = ax.get_figure()\n",
        "# fig2.savefig(path+\"/Data Outputs/bar_music.png\",bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PYnXB9MJ6_Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}